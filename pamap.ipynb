{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from utils.test import Tester\n",
    "from utils.feature_extractor import g_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import torch\n",
    "from utils.pamap_dataset import PAMAP\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import sys\n",
    "from utils.classifier import Classifier\n",
    "import time\n",
    "\n",
    "def same_model(model_g, model_g_1):\n",
    "    are_same = True\n",
    "    for (param_1, value_1), (param_2, value_2) in zip(model_g.state_dict().items(), model_g_1.state_dict().items()):\n",
    "        if param_1 != param_2 or not torch.equal(value_1, value_2):\n",
    "            are_same = False\n",
    "            break\n",
    "\n",
    "    #print(\"Models are the same:\" if are_same else \"Models are different\")\n",
    "    return are_same\n",
    "\n",
    "def split(dataset, samples):\n",
    "    counts = {i: 0 for i in range(6)}  # Assuming labels are from 0 to 11\n",
    "    training = []\n",
    "    testing = []\n",
    "\n",
    "    for a in dataset:\n",
    "        label = a[1]\n",
    "        print(label)\n",
    "        if counts[label] < samples:\n",
    "            training.append(a)\n",
    "            counts[label] += 1\n",
    "        else:\n",
    "            testing.append(a)\n",
    "\n",
    "    return training, testing\n",
    "\n",
    "\n",
    "def load_MHEALTH(train, validation, test):\n",
    "    dataset = PAMAP(train=train, validation=validation, test= test )\n",
    "    dataset.get_datasets()\n",
    "    dataset.preprocessing()\n",
    "    dataset.normalize()\n",
    "    dataset.data_segmentation()\n",
    "    dataset.prepare_dataset()\n",
    "\n",
    "    return dataset.training_final, dataset.validation_final, dataset.testing_final\n",
    "\n",
    "def experiment(distribution):\n",
    "    dist = {1:([3,4,5,6,7,8], [2], [1]),\n",
    "            2:([3,4,5,6,7,8], [1], [2]),\n",
    "            3:([1,4,5,6,7,8], [2], [3]),\n",
    "            4:([1,3,5,6,7,8], [2], [4]),\n",
    "            5:([1,3,4,6,7,8], [2], [5]),\n",
    "            6:([1,3,4,5,7,8], [2], [6]),\n",
    "            7:([1,3,4,5,6,8], [2], [7]),\n",
    "            8:([1,3,4,5,6,7], [2], [8])\n",
    "            }\n",
    "    train,val,test = dist[distribution]\n",
    "    return train, val, test\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0}\n"
     ]
    }
   ],
   "source": [
    "train,val,t = experiment(1)\n",
    "training, validation, test = load_MHEALTH(train,val,t)\n",
    "\n",
    "uci_har_training = []\n",
    "uci_har_validation = []\n",
    "uci_har_test = []\n",
    "\n",
    "\n",
    "for a in training:\n",
    "    uci_har_training.append((a[0],a[1]))\n",
    "for b in validation:\n",
    "    uci_har_validation.append((b[0],b[1]))\n",
    "for c in test:\n",
    "    uci_har_test.append((c[0],c[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class g_function(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv1 = nn.Conv2d(18,16,(1,9))\n",
    "        self.max1 = nn.MaxPool2d((1,2))\n",
    "        self.conv2 = nn.Conv2d(16, 32,(1,9))\n",
    "        self.max2 = nn.MaxPool2d((1,3))\n",
    "        self.linear1 = nn.Linear(1216, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(128,64)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.relu(self.conv1(input))\n",
    "        x = self.max1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.max2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.linear1(torch.squeeze(x)))\n",
    "        x = self.linear2(x)\n",
    "        return torch.squeeze(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 1, 248]           2,608\n",
      "              ReLU-2           [-1, 16, 1, 248]               0\n",
      "         MaxPool2d-3           [-1, 16, 1, 124]               0\n",
      "            Conv2d-4           [-1, 32, 1, 116]           4,640\n",
      "              ReLU-5           [-1, 32, 1, 116]               0\n",
      "         MaxPool2d-6            [-1, 32, 1, 38]               0\n",
      "           Flatten-7                 [-1, 1216]               0\n",
      "            Linear-8                  [-1, 256]         311,552\n",
      "              ReLU-9                  [-1, 256]               0\n",
      "           Linear-10                   [-1, 84]          21,588\n",
      "             ReLU-11                   [-1, 84]               0\n",
      "           Linear-12                   [-1, 64]           5,440\n",
      "================================================================\n",
      "Total params: 345,828\n",
      "Trainable params: 345,828\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.16\n",
      "Params size (MB): 1.32\n",
      "Estimated Total Size (MB): 1.49\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = g_function().cuda()\n",
    "\n",
    "summary(model,(18,1,256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pamap_supervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
